{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Error management utils"
      ],
      "metadata": {
        "id": "U2j8m6MQRX6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "//MACRO TO DEBUG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true) {\n",
        "    if (code != cudaSuccess) {\n",
        "        fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "        if (abort) exit(code);\n",
        "    }\n",
        "}\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZcCzw4RRXCi",
        "outputId": "5789f760-7955-4f09-bc08-9fa9ef0040e5"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1CXQEp-FjsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b409f30a-a438-41fa-f82d-25c520c9a3f4"
      },
      "source": [
        "%%writefile saxpy.cu\n",
        "/*\n",
        " * GPU code of SAPXPY\n",
        " * Y = a.X + Y\n",
        " */\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Vector initialization\n",
        "////////////////////////////////////////////////////////////////\n",
        "void init_tab(float *tab, int len, float val) {\n",
        "    for (int k=0; k<len; k++)\n",
        "      tab[k]= val;\n",
        "}\n",
        "\n",
        "void print_tab(const char *tab_name, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\n 10 first elements of %s: \\n\", tab_name);\n",
        "   for (k=0; k<10; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n 10 lasts : \\n\");\n",
        "   for (k=len-10; k<len; k++)\n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     SAXPY kernel\n",
        "////////////////////////////////////////////////////////////////\n",
        "__global__ void saxpy(float *tabX, float *tabY, int len, float a){\n",
        "   /* Select the right idx */\n",
        "   int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "   if(idx < len)\n",
        "     tabY[idx] = a * tabX[idx] + tabY[idx];\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////\n",
        "//     Main program\n",
        "////////////////////////////////////////////////////////////////\n",
        "int main(int argc, char** argv){\n",
        "    float *tabX_d, *tabX_h;\n",
        "    float *tabY_d, * tabY_h;\n",
        "    int lens[4] = {1000, 10000, 100000, 1000000000};\n",
        "\n",
        "     /** Initialization of the grid **/\n",
        "    // TODO\n",
        "    int blocksize = 1024;\n",
        "    dim3 block(blocksize);\n",
        "\n",
        "    for (int i = 0; i < 4; i++) {\n",
        "      float milliseconds = 0;\n",
        "      cudaEvent_t start, stop;\n",
        "\n",
        "      cudaEventCreate(&start);\n",
        "      cudaEventCreate(&stop);\n",
        "\n",
        "      int len = lens[i];\n",
        "      dim3 grid((len + blocksize - 1) / blocksize);\n",
        "\n",
        "      /** Allocation in host memory **/\n",
        "      tabX_h = (float *) malloc(sizeof(float) * len);\n",
        "      init_tab(tabX_h, len , 5.);\n",
        "      //TODO - allocation and initialization of tabY_h\n",
        "      tabY_h = (float *) malloc(sizeof(float) * len);\n",
        "      init_tab(tabY_h, len, 1.);\n",
        "\n",
        "      /** Allocation in device memory **/\n",
        "      gpuErrchk(cudaMalloc((void**) &tabX_d, sizeof(float) * len));\n",
        "      // TODO - allocation of tabY_d\n",
        "      gpuErrchk(cudaMalloc((void**) &tabY_d, sizeof(float) * len));\n",
        "\n",
        "      /** Pre-print of tabY **/\n",
        "      printf(\"Before computation \\n\");\n",
        "      print_tab(\"tabY_h\",tabY_h, len);\n",
        "\n",
        "      /** Transfer of data from host to device **/\n",
        "      gpuErrchk(cudaMemcpy(tabX_d, tabX_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "      gpuErrchk(cudaMemcpy(tabY_d, tabY_h, sizeof(float) * len, cudaMemcpyHostToDevice));\n",
        "\n",
        "      /** SaxPY kernel launching **/\n",
        "      cudaEventRecord(start);\n",
        "      saxpy<<<grid, block>>>(tabX_d, tabY_d, len, 2.);\n",
        "      cudaEventRecord(stop);\n",
        "      cudaEventSynchronize(stop);\n",
        "\n",
        "      cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "      gpuErrchk(cudaPeekAtLastError());\n",
        "      gpuErrchk(cudaDeviceSynchronize());\n",
        "\n",
        "      /** Transfer of the result from device to host **/\n",
        "      gpuErrchk(cudaMemcpy(tabY_h, tabY_d, sizeof(float) * len, cudaMemcpyDeviceToHost));\n",
        "\n",
        "      /** Affichage du resultat **/\n",
        "      printf(\"\\nAfter computation\\n\");\n",
        "      print_tab(\"tabY_h\", tabY_h, len);\n",
        "\n",
        "      printf(\"\\nTime elapsed (len=%d): %f ms\\n\\n\", len, milliseconds);\n",
        "\n",
        "      /** Memory free **/\n",
        "      cudaFree(tabX_d);\n",
        "      cudaFree(tabY_d);\n",
        "      free(tabX_h);\n",
        "      free(tabY_h);\n",
        "    }\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting saxpy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc -arch=sm_75 saxpy.cu -o saxpy"
      ],
      "metadata": {
        "id": "UF-GcylqnMF9"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./saxpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC4QYWkfnTLQ",
        "outputId": "ea2a83f6-1fa0-4ac6-f17f-c65f745285ee"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before computation \n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            " 10 lasts : \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "\n",
            "After computation\n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            " 10 lasts : \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            "\n",
            "Time elapsed (len=1000): 0.092192 ms\n",
            "\n",
            "Before computation \n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            " 10 lasts : \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "\n",
            "After computation\n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            " 10 lasts : \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            "\n",
            "Time elapsed (len=10000): 0.012288 ms\n",
            "\n",
            "Before computation \n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            " 10 lasts : \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "\n",
            "After computation\n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            " 10 lasts : \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            "\n",
            "Time elapsed (len=100000): 0.012000 ms\n",
            "\n",
            "Before computation \n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            " 10 lasts : \n",
            "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "\n",
            "After computation\n",
            "\n",
            " 10 first elements of tabY_h: \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            " 10 lasts : \n",
            "11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 11.00 \n",
            "\n",
            "Time elapsed (len=1000000000): 45.918369 ms\n",
            "\n"
          ]
        }
      ]
    }
  ]
}